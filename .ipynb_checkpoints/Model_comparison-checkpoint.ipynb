{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0e1566a0-a12b-4d86-a820-55168b1ecb3c",
   "metadata": {},
   "source": [
    "Feature selection and Model Comparison"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f116a82-19ed-46ab-8607-28c59d810430",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c37e37a-1448-40c5-9743-7db800e00556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e49e770-d4ff-4d30-8492-6d6c5af488d3",
   "metadata": {},
   "source": [
    "Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f01f43-9aad-49ef-9719-ec87b72da3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"DataSet/Train.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43fd4db2-98a7-4823-b12a-46464032f66e",
   "metadata": {},
   "source": [
    "Scaling using StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10cacab-9216-418c-9475-5d6d9531186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=train.drop(columns=['ID','Label']).columns\n",
    "target='Label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f1eda7-44ab-45da-8da4-122535d4429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train[features], \n",
    "                                                    train[target].to_frame(),\n",
    "                                                    stratify=train[target], #to account for class imbalance\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfd66767-3f08-4cc2-b233-dcbd7b965289",
   "metadata": {},
   "source": [
    "Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e823fd0-4fc8-4dd9-a9e5-40ffcee8de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3b4fbd-836b-40bf-9b2c-e5cfb32ce178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1923, number of negative: 5203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3109\n",
      "[LightGBM] [Info] Number of data points in the train set: 7126, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "                 Model  Features        F1  Precision    Recall\n",
      "0  Logistic Regression        14  0.527347   0.434140  0.671518\n",
      "1        Random Forest        14  0.942454   0.986364  0.902287\n",
      "2              XGBoost        14  0.957265   0.984615  0.931393\n",
      "3             LightGBM        14  0.957717   0.974194  0.941788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Features\": X_train.shape[1],\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f69485c-93ee-4e3f-a5a0-f24e792df1ac",
   "metadata": {},
   "source": [
    "Now with feature slection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf556dc2-e58e-4511-846d-0601e8152c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def select_features(X_train,y_train,X_test,model):\n",
    "    rfecv=RFECV(\n",
    "        estimator=model,\n",
    "        step=1,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        min_features_to_select=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rfecv.fit(X_train,y_train)\n",
    "\n",
    "    selected=X_train.columns[rfecv.support_]\n",
    "    X_train_fs=X_train[selected]\n",
    "    X_test_fs=X_test[selected]\n",
    "\n",
    "    return X_train_fs,X_test_fs,selected;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ec1ef-eb8a-41f2-b100-fd6e0a72f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manuk\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\manuk\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\manuk\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression selected features:\n",
      "['I/O Data Operations', ' I/O Data Bytes', 'Number of subprocesses', 'Time on processor', 'Disk Reading/sec', 'Disc Writing/sec', 'Bytes Sent/sent', 'Received Bytes (HTTP)', 'Network packets sent', 'Network packets received', 'Pages Read/sec', 'Pages Input/sec', 'Page Errors/sec', 'Confirmed byte radius']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for name,model in models.items():\n",
    "\n",
    "    X_train_fs,X_test_fs,selected=select_features(X_train,y_train,X_test,model)\n",
    "    \n",
    "    model.fit(X_train_fs,y_train)\n",
    "    y_pred = model.predict(X_test_fs)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Features\": len(selected),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred)\n",
    "    })\n",
    "    print(f\"{name} selected features:\")\n",
    "    print(list(selected))\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "results_df=pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4947217c-1e72-41ca-a48e-3b1fcdd0de03",
   "metadata": {},
   "source": [
    "Final Model Selected: LightGBM with feature-selected inputs\n",
    "Justification: Achieved the highest F1-score and recall while using fewer features, indicating superior generalization and suitability for cryptojacking detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
